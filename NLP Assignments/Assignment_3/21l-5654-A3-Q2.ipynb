{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I saved pre processed text in csv file m using that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ایٹم بم بنایا ھے بھائی ایٹم بمب کوٹ لکھپت اتفا...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے انقلاب عمران خان وزیر اعظم بن سکتے</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر خیال</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا فٹ بلندی چھلانگ عال...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اسکی لہریں یار أ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Class\n",
       "0  ایٹم بم بنایا ھے بھائی ایٹم بمب کوٹ لکھپت اتفا...      2\n",
       "1            چندے انقلاب عمران خان وزیر اعظم بن سکتے      0\n",
       "2                                         ٹویٹر خیال      1\n",
       "3  سرچ انجن گوگل نائب صدر فضا فٹ بلندی چھلانگ عال...      2\n",
       "4                                   اسکی لہریں یار أ      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_dataset = pd.read_csv(\"Analysed_Urdu_Tweets.csv\",index_col=False)\n",
    "urdu_dataset.drop(urdu_dataset.columns[0],axis=1,inplace=True)\n",
    "urdu_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (749, 31)\n",
      "Testing set shape: (250, 31)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## WORDS in dataset\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(urdu_dataset['Tweet'])\n",
    "sequences = tokenizer.texts_to_sequences(urdu_dataset['Tweet'])\n",
    "\n",
    "max_sequence_length = max(len(x) for x in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "## Split the dataset\n",
    "# Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, urdu_dataset['Class'], test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\",X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import tensorflow_hub as hub\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "# glove_model = api.load(\"glove-twitter-200\")\n",
    "# fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "# elmo = hub.load(\"https://tfhub.dev/google/elmo/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(seq) for seq in X_train])\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_weights = create_embedding_matrix(word2vec_model, tokenizer)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embed_matrix = np.zeros((vocab_size,word2vec_model.vector_size))\n",
    "\n",
    "for w,i in tokenizer.word_index.items():\n",
    "    if w in word2vec_model:\n",
    "        embed_matrix[i] = word2vec_model[w]\n",
    "word2vec_weights = embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU -> 3,0.7 ->0.66\n",
    "# nested for for dropout and _\n",
    "num_layers =3\n",
    "dropout_rate=0.7\n",
    "\n",
    "embedding_dim = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(GRU(units=64))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "18/18 [==============================] - 25s 268ms/step - loss: 0.0000e+00 - accuracy: 0.2977 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 2/8\n",
      "18/18 [==============================] - 2s 86ms/step - loss: 0.0000e+00 - accuracy: 0.3422 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 3/8\n",
      "18/18 [==============================] - 1s 82ms/step - loss: 0.0000e+00 - accuracy: 0.3672 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 4/8\n",
      "18/18 [==============================] - 1s 81ms/step - loss: 0.0000e+00 - accuracy: 0.4492 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 5/8\n",
      "18/18 [==============================] - 1s 77ms/step - loss: 0.0000e+00 - accuracy: 0.4795 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 6/8\n",
      "18/18 [==============================] - 1s 76ms/step - loss: 0.0000e+00 - accuracy: 0.4938 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 7/8\n",
      "18/18 [==============================] - 1s 75ms/step - loss: 0.0000e+00 - accuracy: 0.4848 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n",
      "Epoch 8/8\n",
      "18/18 [==============================] - 1s 73ms/step - loss: 0.0000e+00 - accuracy: 0.4938 - val_loss: 0.0000e+00 - val_accuracy: 0.5160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d73fab8088>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=8, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = dict()\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "model_eval['GRU(no embedding)'] = {'Precision':precision,'Recall':recall,'F1 score':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GRU(no embedding)': {'Precision': 0.16266666666666665,\n",
       "  'Recall': 0.3333333333333333,\n",
       "  'F1 score': 0.2186379928315412}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word2vec_weights), output_dim=300,weights=[word2vec_weights], input_length=max_length))\n",
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(GRU(units=64))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 33s 380ms/step - loss: 0.0000e+00 - accuracy: 0.1753 - val_loss: 0.0000e+00 - val_accuracy: 0.0067\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0000e+00 - accuracy: 0.3222 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 0.0000e+00 - accuracy: 0.3105 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0000e+00 - accuracy: 0.4324 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0000e+00 - accuracy: 0.4908 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 0.0000e+00 - accuracy: 0.4958 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0000e+00 - accuracy: 0.4891 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0000e+00 - accuracy: 0.4958 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d742342188>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "precision2 = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "recall2 = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "f12 = f1_score(y_test, y_pred, average='macro', zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval['GRU(embedding: word2vec)'] = {'Precision':precision2,'Recall':recall2,'F1 score':f12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Precision    Recall  F1 score\n",
      "GRU(no embedding)          0.162667  0.333333  0.218638\n",
      "GRU(embedding: word2vec)   0.162667  0.333333  0.218638\n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame.from_dict(model_eval, orient='index')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
