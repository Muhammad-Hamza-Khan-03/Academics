{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urdu hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urduhack\n",
      "  Downloading urduhack-1.1.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting tf2crf (from urduhack)\n",
      "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-datasets~=3.1 (from urduhack)\n",
      "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting Click~=7.1 (from urduhack)\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: regex in d:\\python64\\lib\\site-packages (from urduhack) (2023.12.25)\n",
      "Requirement already satisfied: absl-py in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.1.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (23.2.0)\n",
      "Collecting dill (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting future (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numpy in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.21.6)\n",
      "Collecting promise (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.6.1 in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (3.19.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\hamza\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.16.0)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: termcolor in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.3.0)\n",
      "Requirement already satisfied: tqdm in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (4.66.2)\n",
      "Requirement already satisfied: wrapt in d:\\python64\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.16.0)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in d:\\python64\\lib\\site-packages (from tf2crf->urduhack) (2.11.0)\n",
      "Collecting tensorflow-addons>=0.8.2 (from tf2crf->urduhack)\n",
      "  Downloading tensorflow_addons-0.19.0-cp37-cp37m-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: importlib-metadata in d:\\python64\\lib\\site-packages (from attrs>=18.1.0->tensorflow-datasets~=3.1->urduhack) (6.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python64\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python64\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python64\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python64\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2024.2.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in d:\\python64\\lib\\site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (24.3.7)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (3.8.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hamza\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (23.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hamza\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (68.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (4.7.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\python64\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.31.0)\n",
      "Collecting typeguard>=2.7 (from tensorflow-addons>=0.8.2->tf2crf->urduhack)\n",
      "  Downloading typeguard-4.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting absl-py (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hamza\\appdata\\roaming\\python\\python37\\site-packages (from tqdm->tensorflow-datasets~=3.1->urduhack) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\python64\\lib\\site-packages (from importlib-metadata->attrs>=18.1.0->tensorflow-datasets~=3.1->urduhack) (3.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\python64\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\python64\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\python64\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\python64\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\python64\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\python64\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\python64\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\python64\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\python64\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\python64\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\python64\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (1.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\python64\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\python64\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\python64\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.1.0->tf2crf->urduhack) (3.2.2)\n",
      "Downloading urduhack-1.1.1-py3-none-any.whl (105 kB)\n",
      "   -------------------------------------- 105.5/105.5 kB 762.4 kB/s eta 0:00:00\n",
      "Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 82.8/82.8 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
      "   ---------------------------------------- 3.4/3.4 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
      "Downloading tensorflow_addons-0.19.0-cp37-cp37m-win_amd64.whl (742 kB)\n",
      "   ---------------------------------------- 742.5/742.5 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 115.3/115.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 491.3/491.3 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 52.3/52.3 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 126.5/126.5 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 229.1/229.1 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading typeguard-4.1.2-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21545 sha256=6151d52858e5f144a678612a20e41da8d1cca412c89fa148e97772cf9dd6aaa8\n",
      "  Stored in directory: c:\\users\\hamza\\appdata\\local\\pip\\cache\\wheels\\29\\93\\c6\\762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "Successfully built promise\n",
      "Installing collected packages: promise, googleapis-common-protos, future, dill, Click, absl-py, typeguard, tensorflow-metadata, tensorflow-datasets, tensorflow-addons, tf2crf, urduhack\n",
      "  Attempting uninstall: Click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "Successfully installed Click-7.1.2 absl-py-1.4.0 dill-0.3.7 future-1.0.0 googleapis-common-protos-1.63.0 promise-2.3 tensorflow-addons-0.19.0 tensorflow-datasets-3.2.1 tensorflow-metadata-1.12.0 tf2crf-0.1.33 typeguard-4.1.2 urduhack-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fiona 1.9.6 requires click~=8.0, but you have click 7.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install urduhack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urduhack\n",
    "from urduhack.normalization import normalize\n",
    "from urduhack.preprocessing import normalize_whitespace,remove_punctuation,remove_accents,replace_urls,replace_emails,replace_numbers\n",
    ",replace_currency_symbols\n",
    "\n",
    "from urduhack.models.lemmatizer import lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/urduhack/resources/releases/download/word_tokenizer/word_tokenizer.zip\n",
      "36788015/36788015 [==============================] - 10s 0us/step\n",
      "Downloading data from https://github.com/urduhack/resources/releases/download/pos_tagger/pos_tagger.zip\n",
      "2761433/2761433 [==============================] - 1s 0us/step\n",
      "Downloading data from https://github.com/urduhack/resources/releases/download/ner/ner.zip\n",
      "11723346/11723346 [==============================] - 4s 0us/step\n",
      "Downloading data from https://github.com/urduhack/resources/releases/download/lemmatizer/ur_lemma_lookup.zip\n",
      "89078/89078 [==============================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "urduhack.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_dataset = pd.read_csv(\"urdu-sentiment-corpus-v1.tsv\",sep=\"\\t\")\n",
    "urdu_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tweet   1000 non-null   object\n",
      " 1   Class   999 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "urdu_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet    0\n",
      "Class    1\n",
      "dtype: int64\n",
      "After Null values Removed\n",
      " Tweet    0\n",
      "Class    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(urdu_dataset.isna().sum())\n",
    "null_check = urdu_dataset.isna().sum().sum()>0\n",
    "if null_check:\n",
    "    urdu_dataset.dropna(inplace=True)\n",
    "    print(\"After Null values Removed\\n\",urdu_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tweet   999 non-null    object\n",
      " 1   Class   999 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "urdu_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    499\n",
       "P    480\n",
       "O     20\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_dataset.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "urdu_dataset['Class'].value_counts().plot(kind='bar')\n",
    "\n",
    "plt.xlabel('Class Attribute')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Class Attribute')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Class Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "urdu_dataset['Encoded_Class'] = label_encoder.fit_transform(urdu_dataset['Class'])\n",
    "\n",
    "print(urdu_dataset['Encoded_Class'].unique())\n",
    "#0 -> Negative\n",
    "#2 -> Positive\n",
    "#1 -> Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    499\n",
       "2    480\n",
       "1     20\n",
       "Name: Encoded_Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_dataset.Encoded_Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#0 -> Negative\n",
    "#2 -> Positive\n",
    "#1 -> Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>Encoded_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class  Encoded_Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P              2\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N              0\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O              1\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P              2\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P              2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['اب', 'ابھی', 'اپنا', 'اپنے', 'اپنی', 'اٹھا', 'اس', 'اسے', 'اسی', 'اگر', 'ان', 'انہوں', 'انہی', 'انہیں', 'انھیں', 'او', 'اور', 'اے', 'ایسا', 'ایسے', 'ایسی', 'ایک', 'آ', 'آپ', 'آتا', 'آتے', 'آتی', 'آگے', 'آنا', 'آنے', 'آنی', 'آئے', 'آئی', 'آئیں', 'آیا', 'با', 'بڑا', 'بڑے', 'بڑی', 'بعد', 'بعض', 'بلکہ', 'بہت', 'بھی', 'بے', 'پاس', 'پر', 'پہلے', 'پھر', 'تا', 'تاکہ', 'تب', 'تجھ', 'تجھے', 'تک', 'تم', 'تمام', 'تمہارا', 'تمہارے', 'تمھارے', 'تمہاری', 'تمہیں', 'تمھیں', 'تھا', 'تھے', 'تھی', 'تھیں', 'تو', 'تیری', 'تیرے', 'جا', 'جاتا', 'جاتی', 'جاتے', 'جاتی', 'جانے', 'جانی', 'جاؤ', 'جائے', 'جائیں', 'جب', 'جس', 'جن', 'جنہوں', 'جنہیں', 'جو', 'جیسا', 'جیسے', 'جیسی', 'جیسوں', 'چاہیئے', 'چلا', 'چاہے', 'چونکہ', 'حالاں', 'حالانکہ', 'دو', 'دونوں', 'دوں', 'دے', 'دی', 'دیا', 'دیں', 'دیے', 'دیتا', 'دیتے', 'دیتی', 'دینا', 'دینے', 'دینی', 'دیئے', 'ڈالا', 'ڈالنا', 'ڈالنے', 'ڈالنی', 'ڈالے', 'ڈالی', 'ذرا', 'رکھا', 'رکھتا', 'رکھتے', 'رکھتی', 'رکھنا', 'رکھنے', 'رکھنی', 'رکھے', 'رکھی', 'رہ', 'رہا', 'رہتا', 'رہتے', 'رہتی', 'رہنا', 'رہنے', 'رہنی', 'رہو', 'رہے', 'رہی', 'رہیں', 'زیادہ', 'سا', 'سامنے', 'سب', 'سکتا', 'سو', 'سے', 'سی', 'شاید', 'صرف', 'طرح', 'طرف', 'عین', 'کا', 'کبھی', 'کچھ', 'کہہ', 'کر', 'کرتا', 'کرتے', 'کرتی', 'کرنا', 'کرنے', 'کرو', 'کروں', 'کرے', 'کریں', 'کس', 'کسے', 'کسی', 'کہ', 'کہا', 'کہے', 'کو', 'کون', 'کوئی', 'کے', 'کی', 'کیا', 'کیسے', 'کیوں', 'کیونکہ', 'کیے', 'کئے', 'گا', 'گویا', 'گے', 'گی', 'گیا', 'گئے', 'گئی', 'لا', 'لاتا', 'لاتے', 'لاتی', 'لانا', 'لانے', 'لانی', 'لایا', 'لائے', 'لائی', 'لگا', 'لگے', 'لگی', 'لگیں', 'لو', 'لے', 'لی', 'لیا', 'لیتا', 'لیتے', 'لیتی', 'لیکن', 'لیں', 'لیے', 'لئے', 'مجھ', 'مجھے', 'مگر', 'میرا', 'میرے', 'میری', 'میں', 'نا', 'نہ', 'نہایت', 'نہیں', 'نے', 'ہاں', 'ہر', 'ہم', 'ہمارا', 'ہمارے', 'ہماری', 'ہو', 'ہوا', 'ہوتا', 'ہوتے', 'ہوتی', 'ہوتیں', 'ہوں', 'ہونا', 'ہونگے', 'ہونے', 'ہونی', 'ہوئے', 'ہوئی', 'ہوئیں', 'ہے', 'ہی', 'ہیں', 'و', 'والا', 'والوں', 'والے', 'والی', 'وہ', 'وہاں', 'وہی', 'وہیں', 'یا', 'یعنی', 'یہ', 'یہاں', 'یہی', 'یہیں']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'my_urdu_stopwords.txt'\n",
    "STOP_WORDS= \"\"\n",
    "with open(file_path,'r',encoding='utf-8')as file:\n",
    "    urdu_stop_words = file.read().strip()\n",
    "    STOP_WORDS+=urdu_stop_words\n",
    "stopword = STOP_WORDS.split()\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(len(stopword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removestopwords(text,stopwords):\n",
    "    \n",
    "    clean_text = []\n",
    "    stopwords_found = []\n",
    "    ignore = set(stopwords)  # Remove stopwords from text\n",
    "    \n",
    "    for i in text:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        words = [word for word in words if word not in ignore and len(word) > 1]\n",
    "        rem_words = [word for word in words if word in ignore and len(word) > 1]\n",
    "        stop_text = \" \".join(rem_words)\n",
    "        res_text = \" \".join(words)\n",
    "        clean_text.append(res_text)\n",
    "        stopwords_found.append(stop_text)\n",
    "        \n",
    "    return clean_text,stopwords_found\n",
    "def lemmatize_text(text):\n",
    "    lemmetized = \"\"\n",
    "    temp  = lemmatizer.lemma_lookup(text)\n",
    "    for t in temp:\n",
    "        lemmetized+=t[0]+\" \"\n",
    "    return lemmetized.strip()\n",
    "def remove_my_stopwords(text, stopwords):\n",
    "    return \" \".join(word for word in text.split() if word not in stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.DataFrame(columns=['old_text','text'])\n",
    "processed_df['old_text'] = urdu_dataset['Tweet']\n",
    "processed_df['text'] = urdu_dataset.Tweet\n",
    "processed_df['text'] = processed_df.text.apply(normalize)\n",
    "processed_df['text'] = processed_df.text.apply(remove_accents)\n",
    "processed_df['text'] = processed_df.text.apply(remove_punctuation)\n",
    "processed_df['text'] = processed_df.text.apply(replace_emails)\n",
    "processed_df['text'] = processed_df.text.apply(replace_numbers)\n",
    "processed_df['text'] = processed_df.text.apply(replace_currency_symbols)\n",
    "\n",
    "processed_df['cleaned_text'] = processed_df['text'].apply(lambda x: remove_my_stopwords(x, stopword))\n",
    "\n",
    "processed_df['Found_stop_words'] = processed_df['text'].apply(lambda x: any(word in stopword for word in x.split()))\n",
    "\n",
    "processed_df['lemmetized_text'] = processed_df.text.apply(lemmatize_text)\n",
    "processed_df['Class'] = urdu_dataset.Encoded_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_text</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Found_stop_words</th>\n",
       "      <th>lemmetized_text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>میں نے ایٹم بم بنایا ھے او بھائی ایٹم بمب کوٹ ...</td>\n",
       "      <td>ایٹم بم بنایا ھے بھائی ایٹم بمب کوٹ لکھپت اتفا...</td>\n",
       "      <td>True</td>\n",
       "      <td>میں نے ایٹم بم بنایا ھے او بھائی ایٹم بمب کوٹ ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>چندے انقلاب عمران خان وزیر اعظم بن سکتے</td>\n",
       "      <td>True</td>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا</td>\n",
       "      <td>ٹویٹر خیال</td>\n",
       "      <td>True</td>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں   فٹ کی ب...</td>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا فٹ بلندی چھلانگ عال...</td>\n",
       "      <td>True</td>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں فٹ کی بلن...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار أ</td>\n",
       "      <td>اسکی لہریں یار أ</td>\n",
       "      <td>True</td>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار أ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            old_text  ... Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...  ...     2\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...  ...     0\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟  ...     1\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...  ...     2\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ  ...     2\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   old_text          999 non-null    object\n",
      " 1   text              999 non-null    object\n",
      " 2   cleaned_text      999 non-null    object\n",
      " 3   Found_stop_words  999 non-null    bool  \n",
      " 4   lemmetized_text   999 non-null    object\n",
      " 5   Class             999 non-null    int32 \n",
      "dtypes: bool(1), int32(1), object(4)\n",
      "memory usage: 43.9+ KB\n"
     ]
    }
   ],
   "source": [
    "processed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>Encoded_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ایٹم بم بنایا ھے بھائی ایٹم بمب کوٹ لکھپت اتفا...</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے انقلاب عمران خان وزیر اعظم بن سکتے</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر خیال</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا فٹ بلندی چھلانگ عال...</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اسکی لہریں یار أ</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class  Encoded_Class\n",
       "0  ایٹم بم بنایا ھے بھائی ایٹم بمب کوٹ لکھپت اتفا...     P              2\n",
       "1            چندے انقلاب عمران خان وزیر اعظم بن سکتے     N              0\n",
       "2                                         ٹویٹر خیال     O              1\n",
       "3  سرچ انجن گوگل نائب صدر فضا فٹ بلندی چھلانگ عال...     P              2\n",
       "4                                   اسکی لہریں یار أ     P              2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis_df = pd.DataFrame(columns=['word','Class'])\n",
    "# analysis_df.word = processed_df.text_separated.apply(str)\n",
    "# analysis_df.Class = processed_df.Class\n",
    "# analysis_df.head()\n",
    "urdu_dataset['Tweet'] = processed_df['cleaned_text']\n",
    "urdu_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_dataset.to_csv('Analysed_Urdu_Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (749, 3)\n",
      "Testing set shape: (250, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=urdu_dataset.Tweet\n",
    "y = urdu_dataset.Encoded_Class\n",
    "# train_df,test_df = train_test_split(urdu_dataset, test_size=0.25)\n",
    "\n",
    "# print(\"Training set shape:\", train_df.shape)\n",
    "# print(\"Testing set shape:\", test_df.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Bidirectional, Dense, Dropout\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RNN\",\"GRU\",\"LSTM\",\"BiLSTM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_vectorizer = TfidfVectorizer()\n",
    "X_tf = idf_vectorizer.fit_transform(X)\n",
    "X_tf = X_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_tf, y, test_size=0.2, random_state=0)\n",
    "labels = [\"Negative\", \"Positive\"]\n",
    "y_train_TFIDF_onehot = tf.keras.utils.to_categorical(y_train_tf, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 4987)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret initializer identifier: 799",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4536\\799494155.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Create the model with the specified hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         model = Sequential([\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mX_train_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# Add more layers based on the value of layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python64\\lib\\site-packages\\keras\\dtensor\\utils.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlayout_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_layout\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0minit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_instance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# Inject the layout parameter after the invocation of __init__()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python64\\lib\\site-packages\\keras\\layers\\core\\embedding.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python64\\lib\\site-packages\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         raise ValueError(\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[1;34m\"Could not interpret initializer identifier: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret initializer identifier: 799"
     ]
    }
   ],
   "source": [
    "num_layers = [2, 3]\n",
    "dropout_rates = [0.3, 0.7]\n",
    "\n",
    "# Iterate over the hyperparameters and train the models\n",
    "for layers in num_layers:\n",
    "    for rate in dropout_rates:\n",
    "        # Create the model with the specified hyperparameters\n",
    "        model = Sequential([\n",
    "            Embedding(X_train_tf.shape[0],  X_train_tf.shape[1], X_train_tf.shape[0]),\n",
    "            LSTM(64, return_sequences=True, dropout=rate, recurrent_dropout=rate, input_shape=(X_train_tf.shape[1],)),\n",
    "            # Add more layers based on the value of layers\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(X_train_tf, y_train_TFIDF_onehot, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
